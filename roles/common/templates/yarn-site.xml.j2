<?xml version="1.0"?>
<configuration>

  <property>
    <name>yarn.resourcemanager.address</name>
    <value>__MASTER_IP__:8032</value>
    <description>the host is the hostname of the ResourceManager and the port is the port on
    which the clients can talk to the Resource Manager. </description>
  </property>

  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>__MASTER_IP__:8025</value>
    <description>host is the hostname of the resource manager and 
    port is the port on which the NodeManagers contact the Resource Manager.
    </description>
  </property>

  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>__MASTER_IP__:8030</value>
    <description>host is the hostname of the resourcemanager and port is the port
    on which the Applications in the cluster talk to the Resource Manager.
    </description>
  </property>

  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
    <description>shuffle service that needs to be set for Map Reduce to run </description>
  </property>

  <property>
    <name>yarn.nodemanager.address</name>
    <value>0.0.0.0:28091</value>
    <description>the nodemanagers bind to this port</description>
  </property>  

  <property>
    <name>yarn.nodemanager.container-executor.class</name>
    <value>{{ container_executor }}</value>
  </property>

  <property>
    <name>yarn.nodemanager.linux-container-executor.resources-handler.class</name>
    <value>org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler</value>
  </property>
  
  <property>
    <name>yarn.nodemanager.linux-container-executor.cgroups.mount</name>
    <value>{{ cgroups_mount_enable }}</value>
  </property>
  
  <property>
    <name>yarn.nodemanager.linux-container-executor.cgroups.mount-path</name>
    <value>{{ cgroups_mount_dir }}</value>
  </property>

  <property>
    <name>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</name>
    <value>{{ cgroups_hierarchy }}</value>
  </property>

  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>false</value>
  </property>

  <property>
    <name>yarn.log.server.url</name>
    <value>__MASTER_IP__:19888/jobhistory/logs/</value>
  </property>

  <property>
    <name>yarn.nodemanager.local-dirs</name>
    <value>${hadoop.tmp.dir}/yarn/nm-local-dir</value>
  </property>

  <property>
    <name>yarn.nodemanager.recovery.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.nodemanager.recovery.dir</name>
    <value>${hadoop.tmp.dir}/yarn/yarn-recovery</value>
  </property>

  <property>
    <name>yarn.nodemanager.recovery.supervised</name>
    <value>true</value>
  </property>


  <property>
    <name>yarn.nodemanager.resource.percentage-physical-cpu-limit</name>
    <value>70</value>
  </property>

  <property>
    <name>yarn.nodemanager.linux-container-executor.group</name>
    <value>{{ container_executor_group }}</value>
  </property>

  <property>
    <name>yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user</name>
    <value>nobody</value>
  </property>

  <property>
    <name>yarn.nodemanager.process-kill-wait.ms</name>
    <value>180000</value>
  </property>  

  <property>
    <name>yarn.nodemanager.runtime.linux.docker.capabilities</name>
    <value>CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE,DAC_READ_SEARCH,SYS_PTRACE,SYS_ADMIN</value>
  </property>

  <property>
    <name>yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed</name>
    <value>true</value>
  </property> 

  <property>
    <name>yarn.nodemanager.runtime.linux.docker.privileged-containers.acl</name>
    <value>root</value>
  </property>

  <property>
    <name>yarn.nodemanager.pmem-check-enabled</name>
    <value>false</value>
  </property>

  <property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
  </property>

  <property>
    <name>yarn.nodemanager.resource.cpu.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.nodemanager.resource.disk.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.nodemanager.resource.memory.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.nodemanager.resource.network.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.nodemanager.resource.network.interface</name>
    <value>eth0</value>
  </property>

  <property>
    <name>yarn.resourcemanager.am.max-attempts</name>
    <value>3</value>
  </property>

  <property>
    <name>yarn.nodemanager.delete.debug-delay-sec</name>
    <value>300</value>
  </property>

  <property>
    <name>yarn.nodemanager.resource.network.outbound-bandwidth-mbit</name>
    <value>10000</value>
  </property>

  <property>
    <name>yarn.application.classpath</name>
    <value>$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*,$HADOOP_YARN_HOME/share/hadoop/mapreduce/*</value>
  </property>

  <property>
    <name>yarn.nodemanager.runtime.linux.docker.allow-keep-container-on-exit</name>
    <value>true</value>
  </property>

  <property>
    <name>yarn.nodemanager.runtime.linux.docker.white-list-volume-mounts</name>
    <value>/tmp:rw,/etc/passwd:ro</value>
  </property>

</configuration>
